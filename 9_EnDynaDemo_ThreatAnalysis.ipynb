{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1759637910025,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "hv4le5kcwhKg",
    "outputId": "29e4db86-57c1-43f9-eaaf-974f8b040da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_spaCy with google mount.ipynb', '.git', '9_EnDynaDemo_ThreatAnalysis.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Look inside your \"Colab Notebooks\" folder\n",
    "print(os.listdir(\"/content/drive/My Drive/Colab Notebooks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17671,
     "status": "ok",
     "timestamp": 1759637905872,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "9a6f8670",
    "outputId": "01508db0-91ec-4206-d3c7-f04c9dd12d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1759637915284,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "cSxDdtKrQFdg",
    "outputId": "87d0a879-e987-484d-f77c-d8c65a5f2284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/Colab Notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8af6162ec348491d89a5a6d8cbfc0e94",
      "04e06a24e9c442afaeaa08df5e417e5c",
      "ce5c2b4f683d4e36a325c09b2c01c642",
      "28adab0258ee49718e534b191abe0a2f",
      "52c90d9c72b240c7b2584b0c5028c5cb",
      "28b60d2e9fe94b838bf125756fcc445f",
      "20023446372448549804d986d3865fbd",
      "fd797c8c509a40ae9501f09547038e33",
      "5603c0dc13a54000bb1adeb143094e13",
      "a53ff77dec4c418da958cbe308c28071",
      "b0d298bdc5df4f98a8f342d0afea2bd6",
      "223a310a02d74b11a1824844e814772e",
      "470956e3c0494195946b412c5159d594",
      "5df2612f720e4140bf3b63cb266b6854",
      "c9a49acae60946b9940f169929a2f026",
      "8b1b1e44e47741eaa80bf9c23c806edf",
      "ea1bdabdfb8b4829b5e07ceb051f1f09",
      "c1d6ee7734fa40b484812352af3c2b18",
      "a7472bb786e74b1682fa8d4036d83e0e",
      "2d797d72a9814654a6a755385e8bcaed",
      "58d58d46e6e74cacbfa6238b1079ef79",
      "4b12c1fbfc4b46af9f7d914d86715438",
      "65a0863932ce46c4b44f610ff5c5874a",
      "0f8c5862fd6a4cdeaebf5e2a74684b76",
      "b13643b7546f4b30907b2945d1c9aeae",
      "4bad0f4727b54f3f928235e528837487",
      "23645201c35548d6b7f6941b57fd6333",
      "c7341e8877eb4470833dd08939ccd55c",
      "82497260ede64c2ead8a82184c64932f",
      "d4f03e6005b948a480da034cd3b4bc2e",
      "437f6d06b34b43b78ce265d3c6863212",
      "e3d14677982a4f0ebc3bb45fefd15b55",
      "d20ee470cdb04d10abf490075cb1baba",
      "af55385640b5445ba4ff25a91f01ddf7",
      "14abc7cf41c14a97bd569b37196f5287",
      "c9d2b68d49004693bf7b844f745e62cb",
      "d86dfb5754624823949027381d627113",
      "9ebfeaf00c8543fbaec64f4d910bfcec",
      "3bf11140bd414003a33711409d5b31b3",
      "d288b88a61684f33a9cff93892605c0c",
      "d4480e95cdf34f628a2185ed3e25a016",
      "9516a1fd9428438e971a94c067cacb02",
      "74f1d644a13d4ab99a64305139c1a217",
      "de4cdeb1f65e4371b4aad9ca7562f213",
      "79ebaa9c0a874ccf8a586be2aa57b5d3",
      "7f7d7528d1e5449f83d3cb5022310e6f",
      "9ad4d7be7c0b4ad3a9f561b6bd034621",
      "26d23e143e0c46229d5e2c3615e80381",
      "8322e80d5c1e4b24a3bcc02c9daea8a4",
      "7b324b2056ba42d09323af393460fcdc",
      "c4198d9edc754951b1d346436ac861bf",
      "110b50426d214f25b23a5a12a96be402",
      "d81873ce793647919fbd10a90fa074a9",
      "d62c510ee2784eb8ab840c346ede6cb0",
      "0331bb9dd7d24c6288b2ddf91171bd38",
      "c94790278fb54b00b61b13555185451e",
      "bb22220ee22141ab9112d17a3ed28de3",
      "24441707bca943e88e66eab7dd9f76e0",
      "255ba4021cd74267bebfc1722d574ccf",
      "b7239dfe41e64429bb6a2e7ca5299b8f",
      "2ad553d569b0466ebe4b9f642a5871cd",
      "a8837d19d7704fd3bb4c5f5d13427de2",
      "7e3a44a60b2a45e8b3964b8e62c59ffd",
      "926f8272141f448b948ba6156a16ab20",
      "ec3b02aac67d4890b41fb694b7cf9988",
      "6b0f5b61c4bf4ead990c9e1ce9bb6de6",
      "505233997e2047d78c9ab94ce03badd4",
      "7af9bf5558e544c49cb6904b9f4efe59",
      "c81f72219a5d4498868be22a9c3962f1",
      "27e2394eaf8f49cf9d45b2de358cbb97",
      "31fedc5e80e04f07a0fdfd2faf7de175",
      "d70d34c3e6a04a819e7794044fc4e64e",
      "d36bdaa784d54d51874b74dbd9b9c09e",
      "d635da97c60d4b208684df95dafef61e",
      "48165e78b8ff49aba92fb5d278a1bf6a",
      "929cc3f69cc64331a7b65da421d76197",
      "cfb6207e86e1438a9826238d80097876",
      "5d550b4ff5dd435d924e406d573117f9",
      "5f438eb8e2c34c559a661b877a5df1e9",
      "7da00044ba8c465b86c81c89ae55a3e0",
      "d5e3fe495369446a8bb4495e9aba450b",
      "f0d49ec1bbfd463aabe3c4c4d5fafc58",
      "c6518cf4bb5f49f1bcaf967fbcbabb67",
      "8c1e9f38f9fe48db9c42371658dfc6f0",
      "e551c5feef694047ba2e51594128ca61",
      "4176b795006847e29a1b12a528c93405",
      "9a260bc5f87f42419555dcd3d0c29fa3",
      "0596347392d54e1590b032642e051742",
      "4adadca820e4492eaed98fc91203d7f1",
      "cf7c2beb257c4f649ffb963a7386ba40",
      "14fd0cf5eb164e27ae204709d120bf01",
      "31bf7015d18547488e3634c8eedfb6f0",
      "b92b64d7faa4432dafd5bd67b761a705",
      "309585a1a65f42daae83055ed483246c",
      "8e72a60f844e4cd59ebe83d16b91d5de",
      "4a2c9272426245b3b2a3cd258f6a014a",
      "d3276d514fba43ed816ed34be6680dad",
      "ab9363d6b0d34954b43f02f78c32e3dc",
      "c464b64a704f45268ddac9a8b924294b",
      "474177ad30484ee7b63156dcf555ba58",
      "6c514b59353f468c8388804d8adfdc6b",
      "da38d4a4e7894e0588658568a8c684bc",
      "c093e964319d466f9dc01cf98dc0706d",
      "30b23e7e7a324306a7205eb77a82af0b",
      "4c3c491eb25c42bfa26174c26a6dd8b9",
      "b6abcf141db34b9bb0065a13b0b5300f",
      "3b9281096c90487e819a5d704f0f161c",
      "26a34927d45c47b28b3a0ac09bc54ff8",
      "76f3554e1faa4dfc8e93f88b5849a596",
      "bf53a464cb284a2998846773d3343a3e"
     ]
    },
    "executionInfo": {
     "elapsed": 160821,
     "status": "ok",
     "timestamp": 1759508065525,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "UO8xD3Ep1i4M",
    "outputId": "a691ef0d-1282-4b29-eafe-652bcec2e9a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hugging Face models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af6162ec348491d89a5a6d8cbfc0e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223a310a02d74b11a1824844e814772e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a0863932ce46c4b44f610ff5c5874a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af55385640b5445ba4ff25a91f01ddf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ebaa9c0a874ccf8a586be2aa57b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94790278fb54b00b61b13555185451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505233997e2047d78c9ab94ce03badd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d550b4ff5dd435d924e406d573117f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adadca820e4492eaed98fc91203d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474177ad30484ee7b63156dcf555ba58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PROCESSING THREAT INTELLIGENCE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Preprocessing text with spaCy...\n",
      "  - Extracted 6 sentences\n",
      "  - Found 13 named entities\n",
      "\n",
      "Step 2: Extracting CVEs and IOCs...\n",
      "  - CVEs found: ['CVE-2021-44228', 'CVE-2021-45046']\n",
      "  - IP addresses: ['45.67.89.123']\n",
      "  - Domains: ['evil-logging-server.com']\n",
      "\n",
      "Step 3: Classifying threat type with Hugging Face transformers...\n",
      "  - Primary threat: vulnerability exploitation\n",
      "  - Confidence: 99.67%\n",
      "\n",
      "Step 4: Analyzing urgency with Hugging Face sentiment analysis...\n",
      "  - Urgency level: CRITICAL\n",
      "  - Urgency score: 1.00\n",
      "\n",
      "Step 5: Enriching CVEs with NVD data...\n",
      "  - Querying NVD for CVE-2021-44228...\n",
      "  - Querying NVD for CVE-2021-45046...\n",
      "    CVSS Score: 9.0 (CRITICAL)\n",
      "\n",
      "Step 6: Calculating risk scores...\n",
      "  - CVE-2021-45046: Risk Score = 89.96 (CRITICAL)\n",
      "\n",
      "================================================================================\n",
      "FINAL THREAT INTELLIGENCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Threat Type: VULNERABILITY EXPLOITATION\n",
      "Urgency: CRITICAL\n",
      "CVEs Identified: CVE-2021-44228, CVE-2021-45046\n",
      "IOCs Found: 1 IPs, 1 domains\n",
      "\n",
      "Risk Assessment:\n",
      "  CVE-2021-45046: CRITICAL (Score: 89.96/100)\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cybersecurity Threat Intelligence NLP Pipeline\n",
    "Using: spaCy, Hugging Face Transformers, NVD API\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import spacy\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP AND INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# Load spaCy for NER and text processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Hugging Face models for threat classification\n",
    "print(\"Loading Hugging Face models...\")\n",
    "\n",
    "# Zero-shot classification for threat categorization\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Sentiment analysis for urgency detection\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\",\n",
    "                             model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "print(\"Models loaded successfully!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. TEXT PREPROCESSING WITH SPACY\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_text(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Preprocess threat intelligence text using spaCy\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    return {\n",
    "        'original_text': text,\n",
    "        'sentences': [sent.text for sent in doc.sents],\n",
    "        'tokens': [token.text for token in doc if not token.is_stop and not token.is_punct],\n",
    "        'entities': [(ent.text, ent.label_) for ent in doc.ents],\n",
    "        'noun_chunks': [chunk.text for chunk in doc.noun_chunks]\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CVE AND IOC EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "def extract_cves(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract CVE identifiers using regex\n",
    "    \"\"\"\n",
    "    cve_pattern = r'CVE-\\d{4}-\\d{4,7}'\n",
    "    cves = re.findall(cve_pattern, text, re.IGNORECASE)\n",
    "    return list(set([cve.upper() for cve in cves]))\n",
    "\n",
    "def extract_iocs(text: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract Indicators of Compromise (IOCs)\n",
    "    \"\"\"\n",
    "    iocs = {\n",
    "        'ip_addresses': [],\n",
    "        'domains': [],\n",
    "        'file_hashes': [],\n",
    "        'urls': []\n",
    "    }\n",
    "\n",
    "    # IP addresses\n",
    "    ip_pattern = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
    "    iocs['ip_addresses'] = list(set(re.findall(ip_pattern, text)))\n",
    "\n",
    "    # Domains (simplified)\n",
    "    domain_pattern = r'\\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\\.)+[a-zA-Z]{2,}\\b'\n",
    "    iocs['domains'] = list(set(re.findall(domain_pattern, text)))\n",
    "\n",
    "    # MD5 hashes\n",
    "    md5_pattern = r'\\b[a-fA-F0-9]{32}\\b'\n",
    "    iocs['file_hashes'] = list(set(re.findall(md5_pattern, text)))\n",
    "\n",
    "    # URLs\n",
    "    url_pattern = r'https?://[^\\s<>\"{}|\\\\^`\\[\\]]+'\n",
    "    iocs['urls'] = list(set(re.findall(url_pattern, text)))\n",
    "\n",
    "    return iocs\n",
    "\n",
    "# ============================================================================\n",
    "# 4. THREAT CLASSIFICATION WITH HUGGING FACE\n",
    "# ============================================================================\n",
    "\n",
    "def classify_threat_type(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Classify threat type using Hugging Face zero-shot classification\n",
    "    This is where Hugging Face transformers shine!\n",
    "    \"\"\"\n",
    "    # Define threat categories based on MITRE ATT&CK and common threats\n",
    "    threat_categories = [\n",
    "        \"ransomware\",\n",
    "        \"malware\",\n",
    "        \"phishing\",\n",
    "        \"data breach\",\n",
    "        \"DDoS attack\",\n",
    "        \"vulnerability exploitation\",\n",
    "        \"insider threat\",\n",
    "        \"advanced persistent threat\",\n",
    "        \"zero-day exploit\"\n",
    "    ]\n",
    "\n",
    "    # Use Hugging Face transformer for classification\n",
    "    result = classifier(text, threat_categories, multi_label=True)\n",
    "\n",
    "    # Return top 3 threat types with confidence scores\n",
    "    classified = {\n",
    "        'primary_threat': result['labels'][0],\n",
    "        'confidence': result['scores'][0],\n",
    "        'all_threats': dict(zip(result['labels'][:3], result['scores'][:3]))\n",
    "    }\n",
    "\n",
    "    return classified\n",
    "\n",
    "def analyze_urgency(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze threat urgency using sentiment analysis\n",
    "    Negative sentiment + certain keywords = high urgency\n",
    "    \"\"\"\n",
    "    # Get sentiment (positive/negative and confidence)\n",
    "    sentiment = sentiment_analyzer(text[:512])[0]  # Truncate to model limit\n",
    "\n",
    "    # Check for urgency keywords\n",
    "    urgency_keywords = [\n",
    "        'critical', 'immediate', 'urgent', 'active', 'exploit',\n",
    "        'actively exploited', 'in the wild', 'zero-day',\n",
    "        'patch immediately', 'emergency'\n",
    "    ]\n",
    "\n",
    "    urgency_count = sum(1 for keyword in urgency_keywords if keyword.lower() in text.lower())\n",
    "\n",
    "    # Calculate urgency score\n",
    "    sentiment_score = sentiment['score'] if sentiment['label'] == 'NEGATIVE' else 1 - sentiment['score']\n",
    "    keyword_score = min(urgency_count / 3, 1.0)  # Normalize to 0-1\n",
    "\n",
    "    urgency_score = (sentiment_score * 0.4) + (keyword_score * 0.6)\n",
    "\n",
    "    urgency_level = 'CRITICAL' if urgency_score > 0.8 else \\\n",
    "                   'HIGH' if urgency_score > 0.6 else \\\n",
    "                   'MEDIUM' if urgency_score > 0.4 else 'LOW'\n",
    "\n",
    "    return {\n",
    "        'urgency_level': urgency_level,\n",
    "        'urgency_score': urgency_score,\n",
    "        'sentiment': sentiment['label'],\n",
    "        'sentiment_confidence': sentiment['score'],\n",
    "        'urgency_keywords_found': urgency_count\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 5. NVD API ENRICHMENT\n",
    "# ============================================================================\n",
    "\n",
    "def enrich_cve_with_nvd(cve_id: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Fetch CVE details from National Vulnerability Database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            if 'vulnerabilities' in data and len(data['vulnerabilities']) > 0:\n",
    "                vuln = data['vulnerabilities'][0]['cve']\n",
    "\n",
    "                # Extract CVSS score\n",
    "                cvss_score = 'N/A'\n",
    "                cvss_severity = 'N/A'\n",
    "                cvss_vector = 'N/A'\n",
    "\n",
    "                if 'metrics' in vuln:\n",
    "                    if 'cvssMetricV31' in vuln['metrics'] and len(vuln['metrics']['cvssMetricV31']) > 0:\n",
    "                        cvss_data = vuln['metrics']['cvssMetricV31'][0]['cvssData']\n",
    "                        cvss_score = cvss_data.get('baseScore', 'N/A')\n",
    "                        cvss_severity = cvss_data.get('baseSeverity', 'N/A')\n",
    "                        cvss_vector = cvss_data.get('vectorString', 'N/A')\n",
    "\n",
    "                # Extract description\n",
    "                description = 'N/A'\n",
    "                if 'descriptions' in vuln and len(vuln['descriptions']) > 0:\n",
    "                    description = vuln['descriptions'][0]['value']\n",
    "\n",
    "                return {\n",
    "                    'cve_id': cve_id,\n",
    "                    'description': description,\n",
    "                    'cvss_score': cvss_score,\n",
    "                    'cvss_severity': cvss_severity,\n",
    "                    'cvss_vector': cvss_vector,\n",
    "                    'status': 'success'\n",
    "                }\n",
    "\n",
    "        return {'cve_id': cve_id, 'status': 'not_found'}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {'cve_id': cve_id, 'status': 'error', 'error': str(e)}\n",
    "\n",
    "# ============================================================================\n",
    "# 6. RISK SCORING AND PRIORITIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_risk_score(cve_data: Dict, threat_classification: Dict, urgency: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate overall risk score combining multiple factors\n",
    "    This mimics your doctoral research on risk assessment frameworks\n",
    "    \"\"\"\n",
    "    # CVSS score (0-10) - 40% weight\n",
    "    cvss_score = float(cve_data.get('cvss_score', 0)) if cve_data.get('cvss_score') != 'N/A' else 5.0\n",
    "    cvss_normalized = cvss_score / 10.0\n",
    "\n",
    "    # Threat type severity - 30% weight\n",
    "    threat_severity_map = {\n",
    "        'ransomware': 0.95,\n",
    "        'zero-day exploit': 1.0,\n",
    "        'advanced persistent threat': 0.9,\n",
    "        'data breach': 0.85,\n",
    "        'vulnerability exploitation': 0.8,\n",
    "        'malware': 0.75,\n",
    "        'phishing': 0.7,\n",
    "        'DDoS attack': 0.65,\n",
    "        'insider threat': 0.8\n",
    "    }\n",
    "    threat_severity = threat_severity_map.get(threat_classification['primary_threat'], 0.5)\n",
    "\n",
    "    # Urgency - 30% weight\n",
    "    urgency_score = urgency['urgency_score']\n",
    "\n",
    "    # Calculate weighted risk score\n",
    "    risk_score = (\n",
    "        cvss_normalized * 0.4 +\n",
    "        threat_severity * 0.3 +\n",
    "        urgency_score * 0.3\n",
    "    ) * 100\n",
    "\n",
    "    # Determine risk level\n",
    "    risk_level = 'CRITICAL' if risk_score >= 85 else \\\n",
    "                'HIGH' if risk_score >= 70 else \\\n",
    "                'MEDIUM' if risk_score >= 50 else \\\n",
    "                'LOW'\n",
    "\n",
    "    return {\n",
    "        'risk_score': round(risk_score, 2),\n",
    "        'risk_level': risk_level,\n",
    "        'cvss_contribution': round(cvss_normalized * 40, 2),\n",
    "        'threat_contribution': round(threat_severity * 30, 2),\n",
    "        'urgency_contribution': round(urgency_score * 30, 2)\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 7. COMPLETE PIPELINE INTEGRATION\n",
    "# ============================================================================\n",
    "\n",
    "def process_threat_intelligence(raw_text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete end-to-end threat intelligence processing pipeline\n",
    "    This is what their production system likely does!\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESSING THREAT INTELLIGENCE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Step 1: Preprocess with spaCy\n",
    "    print(\"Step 1: Preprocessing text with spaCy...\")\n",
    "    preprocessed = preprocess_text(raw_text)\n",
    "    print(f\"  - Extracted {len(preprocessed['sentences'])} sentences\")\n",
    "    print(f\"  - Found {len(preprocessed['entities'])} named entities\\n\")\n",
    "\n",
    "    # Step 2: Extract CVEs and IOCs\n",
    "    print(\"Step 2: Extracting CVEs and IOCs...\")\n",
    "    cves = extract_cves(raw_text)\n",
    "    iocs = extract_iocs(raw_text)\n",
    "    print(f\"  - CVEs found: {cves}\")\n",
    "    print(f\"  - IP addresses: {iocs['ip_addresses']}\")\n",
    "    print(f\"  - Domains: {iocs['domains']}\\n\")\n",
    "\n",
    "    # Step 3: Classify threat type (Hugging Face!)\n",
    "    print(\"Step 3: Classifying threat type with Hugging Face transformers...\")\n",
    "    threat_classification = classify_threat_type(raw_text)\n",
    "    print(f\"  - Primary threat: {threat_classification['primary_threat']}\")\n",
    "    print(f\"  - Confidence: {threat_classification['confidence']:.2%}\\n\")\n",
    "\n",
    "    # Step 4: Analyze urgency (Hugging Face!)\n",
    "    print(\"Step 4: Analyzing urgency with Hugging Face sentiment analysis...\")\n",
    "    urgency = analyze_urgency(raw_text)\n",
    "    print(f\"  - Urgency level: {urgency['urgency_level']}\")\n",
    "    print(f\"  - Urgency score: {urgency['urgency_score']:.2f}\\n\")\n",
    "\n",
    "    # Step 5: Enrich CVEs with NVD data\n",
    "    print(\"Step 5: Enriching CVEs with NVD data...\")\n",
    "    cve_enrichments = []\n",
    "    for cve in cves:\n",
    "        print(f\"  - Querying NVD for {cve}...\")\n",
    "        enrichment = enrich_cve_with_nvd(cve)\n",
    "        cve_enrichments.append(enrichment)\n",
    "        if enrichment['status'] == 'success':\n",
    "            print(f\"    CVSS Score: {enrichment['cvss_score']} ({enrichment['cvss_severity']})\")\n",
    "    print()\n",
    "\n",
    "    # Step 6: Calculate risk scores\n",
    "    print(\"Step 6: Calculating risk scores...\")\n",
    "    risk_assessments = []\n",
    "    for cve_data in cve_enrichments:\n",
    "        if cve_data['status'] == 'success':\n",
    "            risk = calculate_risk_score(cve_data, threat_classification, urgency)\n",
    "            risk_assessments.append({\n",
    "                'cve_id': cve_data['cve_id'],\n",
    "                **risk\n",
    "            })\n",
    "            print(f\"  - {cve_data['cve_id']}: Risk Score = {risk['risk_score']} ({risk['risk_level']})\")\n",
    "\n",
    "    # Compile final results\n",
    "    results = {\n",
    "        'original_text': raw_text,\n",
    "        'preprocessed': preprocessed,\n",
    "        'cves': cves,\n",
    "        'iocs': iocs,\n",
    "        'threat_classification': threat_classification,\n",
    "        'urgency_analysis': urgency,\n",
    "        'cve_details': cve_enrichments,\n",
    "        'risk_assessments': risk_assessments,\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# ============================================================================\n",
    "# 8. DEMO WITH REAL THREAT INTELLIGENCE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample threat intelligence report (similar to what they'd process)\n",
    "    sample_threat_intel = \"\"\"\n",
    "    CRITICAL SECURITY ALERT: Active exploitation of CVE-2021-44228 (Log4Shell)\n",
    "\n",
    "    Threat actors are actively exploiting the Apache Log4j vulnerability to deploy\n",
    "    ransomware payloads. Multiple ransomware groups including Conti and REvil have\n",
    "    been observed using this vulnerability for initial access.\n",
    "\n",
    "    Technical Details:\n",
    "    - Affected versions: Apache Log4j 2.0-beta9 through 2.14.1\n",
    "    - Attack vector: Remote code execution via JNDI injection\n",
    "    - No authentication required\n",
    "    - CVSS Score: 10.0 (Critical)\n",
    "\n",
    "    Observed malicious infrastructure:\n",
    "    - C2 Server: 45.67.89.123\n",
    "    - Malicious domain: evil-logging-server.com\n",
    "    - Payload hash: 5d41402abc4b2a76b9719d911017c592\n",
    "\n",
    "    IMMEDIATE ACTION REQUIRED: Organizations must patch to Log4j 2.17.0 or later\n",
    "    immediately. This vulnerability is being actively exploited in the wild and\n",
    "    poses critical risk to enterprise networks.\n",
    "\n",
    "    Additional CVE-2021-45046 (related bypass) should also be addressed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process the threat intelligence\n",
    "    results = process_threat_intelligence(sample_threat_intel)\n",
    "\n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL THREAT INTELLIGENCE SUMMARY\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    print(f\"Threat Type: {results['threat_classification']['primary_threat'].upper()}\")\n",
    "    print(f\"Urgency: {results['urgency_analysis']['urgency_level']}\")\n",
    "    print(f\"CVEs Identified: {', '.join(results['cves'])}\")\n",
    "    print(f\"IOCs Found: {len(results['iocs']['ip_addresses'])} IPs, \"\n",
    "          f\"{len(results['iocs']['domains'])} domains\")\n",
    "\n",
    "    if results['risk_assessments']:\n",
    "        print(\"\\nRisk Assessment:\")\n",
    "        for risk in results['risk_assessments']:\n",
    "            print(f\"  {risk['cve_id']}: {risk['risk_level']} \"\n",
    "                  f\"(Score: {risk['risk_score']}/100)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1759637941586,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "ayjeoL51sVBK"
   },
   "outputs": [],
   "source": [
    "!git add 9_EnDynaDemo_ThreatAnalysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1759637996872,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "MGvyPXofmHIh"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"parkd2012@gmail.com\"\n",
    "!git config --global user.name \"Dennis Park\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1759638003457,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "es9-Rbs1RIbc",
    "outputId": "d68e3f32-c3d0-4407-ef4d-6676bfbf66d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean-main 8eee683] 9_EnDynaDemo_ThreatAnalysis.ipynb initial\n",
      " 1 file changed, 1 insertion(+)\n",
      " create mode 100644 9_EnDynaDemo_ThreatAnalysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"9_EnDynaDemo_ThreatAnalysis.ipynb initial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2159,
     "status": "ok",
     "timestamp": 1759632691160,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "L59Dm-ewsiZJ",
    "outputId": "18bc6c86-cb20-49f0-a650-8a4b4186d364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 4, done.\n",
      "Counting objects:  25% (1/4)\r",
      "Counting objects:  50% (2/4)\r",
      "Counting objects:  75% (3/4)\r",
      "Counting objects: 100% (4/4)\r",
      "Counting objects: 100% (4/4), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects:  33% (1/3)\r",
      "Compressing objects:  66% (2/3)\r",
      "Compressing objects: 100% (3/3)\r",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects:  33% (1/3)\r",
      "Writing objects:  66% (2/3)\r",
      "Writing objects: 100% (3/3)\r",
      "Writing objects: 100% (3/3), 13.20 KiB | 1.10 MiB/s, done.\n",
      "Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\n",
      "To https://github.com/parkd2012/endyna_demo.git\n",
      "   f3eb289..557d96b  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1759638338170,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "lDxEkRw4nhhq",
    "outputId": "ade0e2b1-8015-4edc-f23a-ae528f025b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch clean-main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   9_EnDynaDemo_ThreatAnalysis.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1759638475012,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "uokoqLdtoC_5"
   },
   "outputs": [],
   "source": [
    "!git add 9_EnDynaDemo_ThreatAnalysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1759638485730,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "rMKkr8_zoGLa",
    "outputId": "42541fe1-5658-48a6-b0c8-04d6906a21f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch clean-main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\t\u001b[32mmodified:   9_EnDynaDemo_ThreatAnalysis.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1759638507029,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "UokX4fUkoKzw",
    "outputId": "a3fc1d12-469f-4388-bcdc-0d6c1d0c0f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean-main 6770275] Add updated 9_EnDynaDemo_ThreatAnalysis notebook\n",
      " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
      " rewrite 9_EnDynaDemo_ThreatAnalysis.ipynb (81%)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Add updated 9_EnDynaDemo_ThreatAnalysis notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1759638796732,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "9xyB9O8soRa7",
    "outputId": "e137992c-e03f-435c-eb7e-89a177a797df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (9/9), done.\n",
      "Writing objects: 100% (9/9), 16.07 KiB | 470.00 KiB/s, done.\n",
      "Total 9 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (3/3), done.\u001b[K\n",
      "To https://github.com/parkd2012/endyna_demo.git\n",
      " + 31ea6c4...6770275 clean-main -> main (forced update)\n"
     ]
    }
   ],
   "source": [
    "!git push -f origin clean-main:main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1759638685160,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "qQAt4lj5ozzI",
    "outputId": "7b926901-b413-476a-8eaa-3a4b7ce238e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m6770275\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mclean-main\u001b[m\u001b[33m)\u001b[m Add updated 9_EnDynaDemo_ThreatAnalysis notebook\n",
      "\u001b[33m8eee683\u001b[m 9_EnDynaDemo_ThreatAnalysis.ipynb initial\n",
      "\u001b[33m9e671a3\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m)\u001b[m Initial commit without old secrets\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9007,
     "status": "ok",
     "timestamp": 1759638950025,
     "user": {
      "displayName": "D Park",
      "userId": "01558080011266772646"
     },
     "user_tz": 240
    },
    "id": "mYgZ3XYUp1I6",
    "outputId": "26681bf9-519f-4826-9db3-ccf9795d1366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (5.10.4)\n",
      "Collecting nbstripout\n",
      "  Downloading nbstripout-0.8.1-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.27.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.15.0)\n",
      "Downloading nbstripout-0.8.1-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: nbstripout\n",
      "Successfully installed nbstripout-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat nbstripout"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNoz+ZcFr7V9WZq6v3JaRMd",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1u-gowByDJbXdPbkR3VlxkPSs95JS0IZJ",
     "timestamp": 1759637758598
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
